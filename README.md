# Image Compression with an Autoencoder Neural Network

## Intro
In what acted as a final project for my two semester class on neural networks and deep learning, my project partner Austin Perera and I created and presented a poster as a part of Colby College's Liberal Arts Symposium. In this project we used Tensorflow's low level API to build and explore the inner workings of how an autoencoder processes images, and how changes in parameters affect the network's outputs. The results of the explorations were then synthesized and displayed for a poster presentation held during the annual CLAS, or Colby Liberal Arts Symposium. 

## Technologies Used
The code for this project was completely written in python using the low level Tensorflow API, Numpy, as well as Matplotlib for displaying the images. If you would like to mess around with the code in jupyter notebook, you will need to download the MNIST dataset available here, https://www.kaggle.com/datasets/hojjatk/mnist-dataset. The STL-10 dataset is also used but the downloading and splitting of that should be handled by the load_stl10_dataset file. Both datasets need to be placed in a subfolder named "data" for the filepaths in the prewritten code to work.

## Poster
For a full discussion of background, methods, and results, I will point you to our poster, aptly titled "Final Poster.pdf", created for displaying all the relevant details surrounding this project.

## Acknowledgements
While there are acknowledgements on the poster I would like to also place them here. I would like to thank my project partner Austin Perera, Professor Oliver Layton, the Colby Computer Science Department, and finally Colby College for making this project possible.

